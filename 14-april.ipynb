{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "name = 'alice'\n",
    "in_length = 8  # mesage of length 4, so expect output of length 4\n",
    "conv_params = [\n",
    "    [[4, 1, 2], 1], \n",
    "    [[2, 2, 4], 2], \n",
    "    [[1, 4, 4], 1], \n",
    "    [[1, 4, 1], 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self, name, in_length, conv_params):\n",
    "        self.name = name  # a string\n",
    "        self.conv_params = conv_params  # format: [filter_shape, stride]\n",
    "        self.in_length = in_length\n",
    "        self.fc_weights = tf.get_variable(\n",
    "            name=self.name + '_fc_weights', shape=[in_length, in_length],\n",
    "            initializer=tf.contrib.layers.xavier_initializer()\n",
    "        )  # do we want to include biases? others don't\n",
    "        self.conv_weights = [tf.get_variable(\n",
    "            self.name + 'conv_weights'+str(conv_params.index(param)),\n",
    "            shape=param[0], initializer=tf.contrib.layers.xavier_initializer()\n",
    "        )\n",
    "                             for param in self.conv_params]\n",
    "\n",
    "    def fc_layer(self, in_tensor):\n",
    "        # input: a tensor.\n",
    "        # if we generate inputs as lists of binary\n",
    "        # digits like [1,0,1,1,...], then process\n",
    "        # as tf.Variable(binary_message, dtype=tf.float32)\n",
    "\n",
    "        # in_tensor is one of\n",
    "        #     plaintext + key for alice\n",
    "        #     ciphertext + key for bob\n",
    "        #     ciphertext for eve\n",
    "\n",
    "        in_tensor = tf.expand_dims(in_tensor, 1)\n",
    "        return tf.nn.sigmoid(tf.matmul(self.fc_weights, in_tensor))\n",
    "\n",
    "    def conv_layer(self, in_tensor):\n",
    "        # input: a tensor of shape [in_length, 1]\n",
    "        # conv1d needs two 3-dimensional tensors as as input\n",
    "        out_tensor = tf.expand_dims(in_tensor, 0)\n",
    "\n",
    "        # for all but the last layers we use relu\n",
    "        for weights in self.conv_weights[:-1]:\n",
    "            stride = self.conv_params[self.conv_weights.index(weights)][1]\n",
    "            # dictionary would be nicer\n",
    "            out_tensor = tf.nn.relu(\n",
    "                tf.nn.conv1d(out_tensor, weights, stride, padding='SAME')\n",
    "            )  # if problems later, maybe I should have used placeholders?\n",
    "\n",
    "        # for the last layer use a tanh\n",
    "        weights = self.conv_weights[-1]\n",
    "        stride = self.conv_params[self.conv_weights.index(weights)][1]\n",
    "        out_tensor = tf.nn.tanh(\n",
    "           tf.nn.conv1d(out_tensor, self.conv_weights[-1], stride, padding='SAME')\n",
    "        )  # if problems later, maybe I should have used placeholders?\n",
    "\n",
    "        out_tensor = tf.squeeze(out_tensor)\n",
    "\n",
    "        # now round to 0's and 1's\n",
    "        # warning: was getting -0.'s instead of 0's. prob ok but...\n",
    "        out_tensor = tf.ceil(out_tensor)\n",
    "\n",
    "        return out_tensor\n",
    "    \n",
    "    def loss_func(self, name, plaintext, eve_output, bob_output):\n",
    "        # All Nets need to use Eve's loss function\n",
    "        # Eve uses it as a loss function and Alice/Bob use it to build their loss func\n",
    "        \n",
    "        # This should be the L1-Loss of the original plaintext and what Eve decrypted\n",
    "        eveLoss_L1 = tf.reduce_sum(tf.abs(plaintext - eve_output))\n",
    "        \n",
    "        # Then, perform the modification Abadi & Andersen describe in 2.5 of (N/2 - Eve_L1)^2 / (N/2)^2\n",
    "        # This should cause the network to drive Eve towards a 50% bit error rate\n",
    "        eveLoss = tf.pow((plaintext.get_shape().as_list()[0]/2 - eveLoss_L1), 2) / tf.pow((plaintext.get_shape().as_list()[0])/2, 2)\n",
    "        \n",
    "        # Alice & Bob use the same loss function\n",
    "        if self.name == 'alice' or self.name == 'bob':\n",
    "            # Alice and Bob's loss is the L1-loss of [originalPlaintext, key] and what Bob recovered minus eveLoss\n",
    "            aliceBobLoss = tf.reduce_sum(tf.abs(bob_output - plaintext)) - eveLoss\n",
    "            return aliceBobLoss\n",
    "        else:\n",
    "            return eveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = Net(name, in_length, conv_params)\n",
    "\n",
    "B = Net('bob', in_length, conv_params)\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_tensor = [1,0,1,0,1,0,1,0]\n",
    "in_tensor = tf.Variable(in_tensor, dtype=tf.float32)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43095133],\n",
       "       [ 0.44031957],\n",
       "       [ 0.65459198],\n",
       "       [ 0.35066968],\n",
       "       [ 0.35429078],\n",
       "       [ 0.470884  ],\n",
       "       [ 0.25281075],\n",
       "       [ 0.54090756]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_output = A.fc_layer(in_tensor)\n",
    "sess.run(fc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_output = A.conv_layer(fc_output)\n",
    "sess.run(conv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_input = tf.concat(0, [conv_output, in_tensor[-4:]])\n",
    "sess.run(bob_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -0.,  0.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_output = B.conv_layer(B.fc_layer(bob_input))\n",
    "sess.run(bob_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this setup, eve_output has an error of (N/2 - Eve_L1)^2 / (N/2)^2 = (2 - 4)^2 / (2)^2 = 1\n",
    "\n",
    "# Thus, the total bob_loss should be whatever the L1 difference is of bob_output and plaintext (in this case, 2) and subtract 1\n",
    "bob_loss = B.loss_func(name='bob', plaintext=in_tensor[0:4],\n",
    "                       eve_output=[0, 1, 0, 1], bob_output=bob_output)\n",
    "sess.run(bob_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
